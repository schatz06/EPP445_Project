{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eye_landamarks_recognition_model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schatz06/EPP445_Project/blob/main/eye_landamarks_recognition_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMHASRsNx_WU"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjaydGdNhFTf"
      },
      "source": [
        "Import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZndBpti9hIu7"
      },
      "source": [
        "import cv2\n",
        "import dlib\n",
        "import os\n",
        "import re"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct2WMpJwq0pb"
      },
      "source": [
        "!wget http://dlib.net/files/data/ibug_300W_large_face_landmark_dataset.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdcK4-5frgOE"
      },
      "source": [
        "!tar xvzf ibug_300W_large_face_landmark_dataset.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubMnt8oKtwG-"
      },
      "source": [
        "Regex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EshJoGsftxjF"
      },
      "source": [
        "REG_PART = re.compile(\"part name='[0-9]+'\")\n",
        "REG_NUM = re.compile(\"[0-9]+\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gjj_C6QZqsDR"
      },
      "source": [
        "Function that parse the xml file of the train data to get the parts of the face that we want to train our predictor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-PF8F6docpw"
      },
      "source": [
        "def parse_xml(input_path,output_path, parts):\n",
        "  file = open(input_path,\"r\") # Open the xml file with the training data\n",
        "  out_file = open(output_path,\"w\") # Open a file descriptor to write the parsed xml file\n",
        "  point_set = set(parts) #create a set with all the parts I want to traing my model\n",
        "\n",
        "  for line in file.readlines():\n",
        "    finds = re.findall(REG_PART,line)\n",
        "\n",
        "    #Trying to find the part section we want\n",
        "    if len(finds) <= 0:\n",
        "      out_file.write(line)\n",
        "    else:\n",
        "      #Here we found a part section\n",
        "      #So we take the part's name and the x,y coordinates\n",
        "      name, x, y = re.findall(REG_NUM,line)\n",
        "\n",
        "      #Here we check if a part's name match with what we are looking for and then write to output file\n",
        "      if int(name) in point_set:\n",
        "        out_file.write(f\"      <part name='{name}' x='{x}' y='{y}'/>\\n\")\n",
        "\n",
        "  out_file.close()\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MYaw78auPMl"
      },
      "source": [
        "THIS PARAMETER determines which parts of the face we want to choose for the training, In our example is the left and right eye"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQnad--AhyzJ"
      },
      "source": [
        "EYES = [i for i in range(36,48)]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rFh_HA9r1zr"
      },
      "source": [
        "This method set the options for our model and trains the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX1kZRI8rJN5"
      },
      "source": [
        "def train_model(name,xml):\n",
        "  # Here we configure the training options\n",
        "  options = dlib.shape_predictor_training_options()\n",
        "  options.tree_depth = 3\n",
        "  options.nu = 0.1\n",
        "  options.cascade_depth = 10\n",
        "  options.feature_pool_size = 150\n",
        "  options.num_test_splits = 350\n",
        "  options.oversampling_amount = 5\n",
        "  options.oversampling_translation_jitter = 0\n",
        "  options.be_verbose = True\n",
        "  options.num_threads = 1\n",
        "\n",
        "  dlib.train_shape_predictor(xml, name, options)\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VAoVVDxu1eV"
      },
      "source": [
        "This method measures the error of the model on the given xml file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmNrKKivuubM"
      },
      "source": [
        "def measure_model_error(model,xml_annotations):\n",
        "  error = dlib.test_shape_predictor(xml_annotations, model)\n",
        "  print(\"Error of the model: {} is {}\".format(model, error))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiRak3phvEsO",
        "outputId": "f75cdf0b-aed4-4e62-aeb4-9c94ac7bfb1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  ibug_xml_train = \"ibug_300W_large_face_landmark_dataset/labels_ibug_300W_train.xml\"\n",
        "  ibug_xml_test = \"ibug_300W_large_face_landmark_dataset/labels_ibug_300W_test.xml\"\n",
        "  eyes_xml_train = \"ibug_300W_large_face_landmark_dataset/eyes_train.xml\"\n",
        "  eyes_xml_test = \"ibug_300W_large_face_landmark_dataset/eyes_test.xml\"\n",
        "  eyes_dat = \"eyes.dat\"\n",
        "\n",
        "  #parse the TRAIN xml and create the new one with only the eyes annotations\n",
        "  parse_xml(ibug_xml_train, eyes_xml_train, parts = EYES)\n",
        "  print(\"Hello1\")\n",
        "  \n",
        "  #parse the TEST xml and create the new one with only the eyes annotations\n",
        "  parse_xml(ibug_xml_test, eyes_xml_test, parts = EYES)\n",
        "  print(\"Hello2\")\n",
        "\n",
        "  #Here we train the eye model\n",
        "  train_model(eyes_dat, eyes_xml_train)\n",
        "\n",
        "  #And last we measure the training and test error\n",
        "  measure_model_error(eyes_dat, eyes_xml_train)\n",
        "  measure_model_error(eyes_dat, eyes_xml_test)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-4eedcc95448b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m#parse the TRAIN xml and create the new one with only the eyes annotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mparse_xml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mibug_xml_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meyes_xml_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEYES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hello1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'EYES' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VL1sIq_0hneR"
      },
      "source": [
        "Here we define the landmark point for the eyes.\n",
        "\n",
        "*   68 point in a face\n",
        "*   22 points for eyes and eyebrows\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNO2si08lB75"
      },
      "source": [
        "Dataset used iBug 300W\n",
        "\n",
        "\n",
        "*   Download\n",
        "*   Extract\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPoO0px5t9g_"
      },
      "source": [
        "Paths "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOQ7h7DQuR8Z"
      },
      "source": [
        ""
      ]
    }
  ]
}